{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial7/GNN_overview.html\n",
    "# https://pytorch-lightning.readthedocs.io/en/stable/notebooks/course_UvA-DL/06-graph-neural-networks.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\home\\AppData\\Local\\Temp\\ipykernel_25476\\778004803.py:12: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('svg', 'pdf') # For export\n"
     ]
    }
   ],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "from matplotlib.colors import to_rgb\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "import seaborn as sns\n",
    "sns.reset_orig()\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Progress bar\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "# Torchvision\n",
    "import torchvision\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Path to the folder where the datasets are/should be downloaded (e.g. CIFAR10)\n",
    "DATASET_PATH = \"./data\"\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = \"./checkpoint\"\n",
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.determinstic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/\"\n",
    "pretrained_files = [\"NodeLevelMLP.ckpt\", \"NodeLevelGNN.ckpt\", \"GraphLevelGraphConv.ckpt\"]\n",
    "\n",
    "# Create checkpoint path if it doesn't exist yet\n",
    "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
    "\n",
    "# For each file, check whether it already exists. If not, try downloading it.\n",
    "for file_name in pretrained_files:\n",
    "    file_path = os.path.join(CHECKPOINT_PATH, file_name)\n",
    "    if \"/\" in file_name:\n",
    "        os.makedirs(file_path.rsplit(\"/\",1)[0], exist_ok=True)\n",
    "    if not os.path.isfile(file_path):\n",
    "        file_url = base_url + file_name\n",
    "        print(f\"Downloading {file_url}...\")\n",
    "        try:\n",
    "            urllib.request.urlretrieve(file_url, file_path)\n",
    "        except HTTPError as e:\n",
    "            print(\"Something went wrong. Please try to download the file from the GDrive folder, or contact the author with the full output including the following error:\\n\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNLayer(nn.Module):\n",
    "  def __init__(self, c_in, c_out):\n",
    "    super().__init__()\n",
    "    self.projection = nn.Linear(c_in, c_out)\n",
    "\n",
    "  def forward(self, node_feats, adj_matrix):\n",
    "    \"\"\"\n",
    "    node_feats [batch_size, num_nodes, c_in]  \n",
    "    adj_matrix [batch_size, num_nodes, num_nodes]\n",
    "    non-symmetric matrices => directed edges\n",
    "    Assume already have added the identity connections\n",
    "    \"\"\"\n",
    "    num_neighbours = adj_matrix.sum(dim=-1, keepdims=True)\n",
    "    node_feats = self.projection(node_feats)\n",
    "    node_feats = torch.bmm(adj_matrix, node_feats)\n",
    "    node_feats = node_feats / num_neighbours\n",
    "    return node_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node features :\n",
      " tensor([[[0., 1.],\n",
      "         [2., 3.],\n",
      "         [4., 5.],\n",
      "         [6., 7.]]])\n",
      "\n",
      "Adjacency metrix:\n",
      " tensor([[[1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "node_feats = torch.arange(8, dtype=torch.float32).view(1,4,2)\n",
    "adj_matrix = torch.tensor([[[1, 1, 0, 0],\n",
    "                           [1,1,1,1],\n",
    "                           [0,1,1,1],\n",
    "                           [0,1,1,1]]], dtype=torch.float32)\n",
    "print(\"Node features :\\n\", node_feats)\n",
    "print(\"\\nAdjacency metrix:\\n\", adj_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency matrix tensor([[[1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.]]])\n",
      "Input features tensor([[[0., 1.],\n",
      "         [2., 3.],\n",
      "         [4., 5.],\n",
      "         [6., 7.]]])\n",
      "Output features tensor([[[1., 2.],\n",
      "         [3., 4.],\n",
      "         [4., 5.],\n",
      "         [4., 5.]]])\n"
     ]
    }
   ],
   "source": [
    "layer = GCNLayer(c_in=2, c_out=2)\n",
    "layer.projection.weight.data = torch.tensor([[1.0, 0.0], [0.0, 1.0]])\n",
    "layer.projection.bias.data = torch.tensor([0.0, 0.0])\n",
    "\n",
    "with torch.no_grad():\n",
    "    out_feats = layer(node_feats, adj_matrix)\n",
    "\n",
    "print(\"Adjacency matrix\", adj_matrix)\n",
    "print(\"Input features\", node_feats)\n",
    "print(\"Output features\", out_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.nn as pyg_nn\n",
    "import torch_geometric.data as pyg_data\n",
    "import torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_layer_by_name = {'GCN':pyg_nn.GCNConv,\n",
    "                     'GAT':pyg_nn.GATConv,\n",
    "                     'GraphConv' : pyg_nn.GraphConv}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "cora_dataset = torch_geometric.datasets.Planetoid(root=DATASET_PATH, name='Cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cora_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNModel(nn.Module):\n",
    "  def __init__(self, c_in, c_hidden, c_out, num_layers=2, layer_name='GCN',\n",
    "               dp_rate=0.1, **kwargs):\n",
    "    \"\"\"\n",
    "    c_in - Dimension of input features\n",
    "    c_hidden - Dimension of hidden features\n",
    "    c_out - Dimension of the output features. Usually number of classes in classification\n",
    "    num_layers - Number of \"hidden\" graph layers\n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "    gnn_layer = gnn_layer_by_name[layer_name]\n",
    "\n",
    "    layers = []\n",
    "    in_channels, out_channels = c_in, c_hidden\n",
    "    for l_idx in range(num_layers-1):\n",
    "      layers += [gnn_layer(in_channels=in_channels, \n",
    "                           out_channels=out_channels,\n",
    "                           **kwargs),\n",
    "                 nn.ReLU(inplace=True),\n",
    "                 nn.Dropout(dp_rate)]\n",
    "      in_channels = c_hidden\n",
    "    \n",
    "    layer += [gnn_layer(in_channels=in_channels, \n",
    "                        out_channels=c_out,\n",
    "                        **kwargs)]\n",
    "    self.layers = nn.ModuleList(layers)\n",
    "  \n",
    "  def forward(self, x, edge_index):\n",
    "    for l in self.layers:\n",
    "      if isinstance(l, pyg_nn.MessagePassing):\n",
    "        x = l(x, edge_index)\n",
    "\n",
    "      else:\n",
    "        x = l(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPModel(nn.Module):\n",
    "  def __init__(self, c_in, c_hidden, c_out, num_layers=2, dp_rate=0.1):\n",
    "    super().__init__()\n",
    "    in_channels, out_channels = c_in, c_hidden\n",
    "    layers = []\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the models into a PL module\n",
    "class NodeLevelGNN(pl.LightningModule):\n",
    "  def __init__(self, model_name, **model_kwargs):\n",
    "    super().__init__()\n",
    "    self.save_hyperparameters()\n",
    "\n",
    "\n",
    "    if model_name == 'MLP':\n",
    "      self.model = MLPModel(**model_kwargs)\n",
    "\n",
    "    else:\n",
    "      self.model = GNNModel(**model_kwargs)\n",
    "\n",
    "    self.loss_module = nn.CrossEntropyLoss()\n",
    "\n",
    "  def forward(self, data, mode='train'):\n",
    "    x, edge_index = data.x, data.edge_index\n",
    "    x = self.model(x, edge_index)\n",
    "\n",
    "    if mode == 'train':\n",
    "      mask = data.train_mask\n",
    "    elif mode == 'val':\n",
    "      mask = data.val_mask\n",
    "    elif mode == 'test':\n",
    "      mask = data.test_mask\n",
    "    else:\n",
    "      assert False, f'Unknown forward mode : {mode}'\n",
    "    \n",
    "    loss = self.loss_module(x[mask], data.y[mask])\n",
    "    acc = (x[mask].argmax(dim=-1) == data.y[mask]).sum().float()/mask.sum()\n",
    "    return loss, acc\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    optimizer = optim.SGD(self.parameters(), lr=0.1, momentum=0.9, weight_decay=2e-3)\n",
    "    return optimizer\n",
    "  \n",
    "  def training_step(self, batch, batch_idx):\n",
    "    loss, acc = self.forward(batch, mode='train')\n",
    "    self.log('train_loss', loss)\n",
    "    self.log('train_acc', acc)\n",
    "    return loss\n",
    "  def validation_step(self, batch, batch_idx):\n",
    "    _, acc = self.forward(batch, mode=\"val\")\n",
    "    self.log('val_acc', acc)\n",
    "  \n",
    "  def test_step(self, batch, batch_idx):\n",
    "    _, acc = self.forward(batch, mode=\"test\")\n",
    "    self.log('test_acc', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_node_classifier(model_name, dataset, **model_kwargs):\n",
    "  pl.seed_everything(42)\n",
    "  node_data_loader = pyg_data.DataLoader(dataset, batch_size=1)\n",
    "\n",
    "  root_dir = os.path.join(CHECKPOINT_PATH, 'NodeLevel'+model_name)\n",
    "  os.makedirs(root_dir, exist_ok=True)\n",
    "\n",
    "  trainer = pl.Trainer(default_root_dir=root_dir,\n",
    "                       callbacks=)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4abfb519203d995b9d5e89b19563ce8f3315dbc6929e3e62f49f954ab0099c11"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('gnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
